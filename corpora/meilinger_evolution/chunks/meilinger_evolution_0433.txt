vitably involve significant costs for the state concerned, 58 and these might well exceed the benefits, if any, expected from previous promises. Of course, although one need not automatically believe an adversary’s threat, even a dubiously credible threat of annihilation  may concentrate the mind and carry deterrent weight. Credibility is an especially significant and potentially problematic issue in two types of scenarios. One involves extended deterrence —threats to retaliate  in response to an attack against a third party or other peripheral interest. 59 The other involves situations in which an enemy launches a limited attack, presenting the victim with a choice between backing down and avoiding additional destruction or responding to the attack and risking escalation to an all-out nuclear exchange, which would prove catastrophic for both sides. 60 Making the response automatic would solve credibility problems posed by the possibility of a leader’s unwillingness in the breach to launch a threatened retaliatory  strike. This possibility found its apotheosis in Herman Kahn ’s hypothetical invention of the “doomsday machine ,” an automated system that would trigger nuclear retaliation  in the event of attack without (or in spite of) human involvement— later immortalized in Dr. Strangelove .61 The United States never opted to remove the human element from its deterrent threats, although some evidence exists that the Soviets did adopt a system to launch some of their missiles  autonomously if the national leadership were incapacitated by an attack. 62 However, the “dead hand” was also at work in the West. For example, the fact that SSBN  crews might choose to launch their weapons on their own initiative if their leaders and country were destroyed served to bolster the American threat of assured destruction  against the possibility of decapitation .63 An additional variation on the doomsday machine  theme appeared in the 1980s, when scientists discovered that a massiv