g to develop standards for autonomous weapons systems. If properly designed, these systems will allow for more careful and caring war, such authorities insist. For sure, obedience to the requirement to avoid civilian harm can be programmed into robots; in future wars, they can gather on their own what human leadership needs to know before a strike is approved.  HUMANE | 320 | EPILOGUE In spite of the possibility that machines will bring us even more humanity in war, the arguments of the new abolitionists are strong. The natural concern is that these new machines will be- come "slaughterbots." They will repeat the pattern of promising to be even more precise than clumsy prior tools of war, only to be- come even more grievously fatal than before, and to more innocent people. Either they will-like the airplane kill on a more massive scale than before or they will-like the drone-allow discrimina- tion of targets in some episodes but rain down more death through more operations. States spending billions in a new arms race for new technologies have rejected these concerns. In time-honored fashion, great powers and other states in a posi- tion to benefit from the revolution in means of warfare have insisted that the alternative of banning robot war in advance is even less hu- mane. Do humanitarians really want that outcome? Can they seriously argue for what may be more violence rather than less? And these states have agreed with alacrity that-while new law is not needed, and especially not a moratorium or prohibition-the existing "in- ternational humanitarian law" of war applies even when humans are no longer in the driver's seat or the drone operator's chair. For now, the talk in diplomatic circles is of norms of "appropriate standards of human judgment" or "meaningful human control" pending bet- ter understanding of what these autonomous machines can do-and how soon. Just as with armed drones before, the short-term question on both sides of the debate is whether autonomo